# 为什么要有锁

锁是为了处理并发问题

> 作为多用户共享的资源，当出现并发访问时，数据库需要合理地`控制资源的访问`



# 锁的分类

根据加锁的范围，MySQL 的锁大致可以分成

1. 全局锁
2. 表级锁
3. 行锁



## 全局锁

即对`整个数据库`实例加锁。



`加全局读锁`的命令FTWRL

```sql
flush tables with read lock // FTWRL
```



加完全局读锁后，整个库处于`只读状态`，其他线程的以下语句会被阻塞

* 数据更新语句（数据的增删改DML）
* 数据定义语句（包括建表、修改表结构等DDL）
* 更新类事务的提交语句



### 使用场景:全库备份

做`全库逻辑备份`，也就是把整库每个表都 select 出来存成文本

> 通过 `FTWRL` 确保不会有其他线程`对数据库做更新`，然后对整个库做备份



在备份过程中整个库完全处于`只读状态`

* 如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆

* 如果在从库上备份，那么备份期间`从库不能执行主库同步过来的binlog`，会导致`主从延迟`



#### 备份不加全局锁有什么问题

也就是不加锁的话，备份系统备份得到的库不是一个逻辑时间点，这个`视图是逻辑不一致`的。



假设现在要维护一个课程购买系统，关注的是`用户账户余额表`和`用户课程表`，现在发起一个`逻辑备份`。

假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课



如果时间顺序上是先备份`账户余额表 (u_account)`，然后用户购买，然后`备份用户课程表 (u_course)`，会怎么样呢？如图：

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/06_%E9%94%81_01.png)

这个备份结果里，用户 A 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。



###  FTWRL和mysqldump

官方自带的逻辑备份工具是` mysqldump`



当 mysqldump 使用参数`–single-transaction `时，导数据之前就会`启动一个事务`，来确保拿到`一致性视图（一致性读）`。而由于MVCC的支持，这个过程中数据是可以正常更新的

> mysqldump 使用参数`–single-transaction `只适用于所有的表使用事务引擎的库(InnoDb)

对于全部是 InnoDB 引擎的库，建议选择使用`–single-transaction `参数，对应用会更友好。



**有了mysqldump，为什么还需要 FTWRL **

`一致性读`的前提是`引擎要支持这个隔离级别`，如果表用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法

> 比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时就需要使用 FTWRL 命令了



#### readonly全库只读

`set global readonly=true`也能让`全库进入只读状态`，为什么还是`建议用 FTWRL 方式`?

主要有两个原因：

1. 有些系统`readonly 的值会被用来做其他逻辑`，比如用来判断一个库是主库还是备库。因此修改 global 变量的方式影响面更大

2. 在`异常处理机制`上有差异

   > 执行 FTWRL 命令之后由于`客户端发生异常断开`，那么 MySQL 会`自动释放这个全局锁`，整个库回到可以正常更新的状态
   >
   > 而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高



## 表锁(2种)

表锁一般是在`数据库引擎不支持行锁`时才会被用到的



1. 表锁
2. 元数据锁（meta data lock，MDL)



### 1、表锁

**加表锁的命令(与 FTWRL 类似)**

```bash
lock tables 表名 read/write
```

> lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象



**释放表锁命令**

```bash
unlock tables // 主动释放被当前会话持有的任何锁
```

> 也可以在客户端断开时自动释放



**举个例子**

1. 在线程 A 中执行 `lock tables t1 read, t2 write; `
2. 其他线程写 t1、读写 t2 的语句都会被阻塞
3. 同时，线程 A 在执行 unlock tables 之前，也只能执行`读 t1`、`读写 t2` 的操作。连写 t1 都不允许，自然也不能访问其他表



### 2、元数据锁(MDL)

metadata lock，MDL不需要显式使用，在访问一个表时系统会`自动加上`

> 在MySQL 5.5 版本中引入了 MDL



**MDL 的作用**

保证读写的正确性

> 因为如果一个查询正在遍历一个表的数据，而此时另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定不行



**加MDL读锁**

对表做`增删改查`操作时



**加MDL写锁**

对表做`结构变更`操作时



**互斥性**

* 读锁之间不互斥，多个线程可以同时对一张表增删改查

* `读锁和写锁`之间、`写锁之间`是互斥的，用来保证变更表结构操作的安全性

  > 如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行



### 如何安全地给小表加字段

经常有人给一个小表加个字段，导致整个库挂了。



给一个表加字段，或者修改字段，或者加索引，需要`扫描全表`的数据

> 即使是小表，操作不慎也会出问题



**加MDL锁阻塞的例子**

来看下面的操作序列，假设表 t 是一个小表

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/06_%E9%94%81_02.jpg)

1. session A 先启动执行select语句，这时会对表 t 加一个 `MDL 读锁`

2. session B 执行select也是加` MDL 读锁`，因此可以正常执行select

3. session C 会被阻塞

   > 因为` session A 的 MDL读锁`还没有释放，而 session C 需要加 `MDL写锁`，因此只能被`阻塞`



**注意：**

session C被阻塞后，之后`所有要在表t上新申请MDL读锁的请求也会被session C阻塞`，等于`这个表`现在完全不可读写了（可以参考文章https://blog.csdn.net/q2878948/article/details/96430129）



**如何为表加字段**

如果某个表上的`查询语句频繁`，而且客户端有`重试机制`，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。



事务中的 MDL 锁，在`语句执行开始时`申请，但是语句结束后并不会马上释放，而会等到`整个事务提交后再释放`。

> 在做表结构变更时，一定要小心不要导致锁住线上查询和更新。

首先要解决长事务，事务不提交，就会一直占着 `MDL 锁`。如果要做 DDL 变更的表刚好有长事务在执行，要考虑`先暂停 DDL`，或者` kill 掉这个长事务`



**怎么查看当前执行中的事务**

> 可从MySQL 的 information_schema 库的 innodb_trx 表中查



场景：如果要变更的表是一个`热点表`，虽然数据量不大，但是上面的请求很频繁，而不得不加个字段，该怎么做？

> 这时 kill 可能未必管用，因为新的请求马上就来了

比较理想的机制是，在` alter table 语句里面设定等待时间`，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过`重试命令`重复这个过程。



MariaDB 已经`合并了AliSQL `的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。

```sql
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ...
```



## 行锁

行锁就是针对数据表中`行记录`的锁

> 比如事务 A 更新了一行，而这时事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新



MySQL 的`行锁`是在`引擎层`由各个引擎自己实现的

> InnoDB 支持行锁；
>
> MyISAM 引擎就不支持行锁(只能使用表锁，同一张表上任何时刻只能有一个更新在执行，这会影响到业务并发度)



### 两阶段锁

**两阶段锁协议**

在 InnoDB 事务中，行锁是在`需要的时候才加上的`，但并不是不需要了就立刻释放，而是要`等到事务结束时才释放`，这个就是`两阶段锁协议`。



在下面的操作序列中，`事务B 的 update 语句`执行时会是什么现象？

> 假设字段 id 是表 t 的主键

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/07_%E8%A1%8C%E9%94%81_01.jpg)

事务 A 在执行完两条 update 语句后，持有的id为1和id为2的`两条记录的行锁`，都是在 commit 的时候才释放的；

实际上事务 B 的 update 语句会`被阻塞`，直到事务 A 执行 commit 之后，事务 B 才能继续执行



**建议**

如果事务中需要`锁多个行`，要把`最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放`



**举例：**

假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票

这个业务需要涉及到以下操作：

1. 从顾客 A 账户余额中扣除电影票价
2. 给影院 B 的账户余额增加这张电影票价
3. 记录一条交易日志

要完成这个交易，需要 update 两条记录，并 insert 一条记录。



当然，为了保证交易的原子性，要把这三个操作放在一个事务中。那么怎样安排这三个语句在事务中的顺序呢？



如果同时有另外一个顾客 C 要在影院 B 买票，那么`这两个事务冲突的部分就是语句2 了`。因为它们要更新同一个影院账户的余额，需要`修改同一行数据`。



根据两阶段锁协议，不论怎样`安排语句顺序`，所有的操作需要的行锁都是在事务提交的时候才释放的。

所以，如果你`把语句 2 安排在最后`，比如按照 3、1、2 这样的顺序，那么`影院账户余额这一行的锁时间就最少`。

这就最大程度地减少了事务之间的锁等待，`提升了并发度`。



如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始时，你的 MySQL 就挂了，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？

这里，我就要说到死锁和死锁检测了。



### 死锁和死锁的检测

**死锁**

当并发系统中`不同线程`出现`循环资源依赖`，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入`无限等待`的状态，称为`死锁`



用数据库中的行锁举个例子：

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/07_%E8%A1%8C%E9%94%81_02.jpg)



事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了`死锁状态`。



```mysql
// 如果开启了死锁检测innodb_deadlock_detect，当事务b执行update t set k = k+1 where id = 1;报如下错，提示有死锁
ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

// 如果关闭了死锁检测，则超时innodb_lock_wait_timeout后报如下错误
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
```



**减少死锁的主要方向**

就是控制访问相同资源的并发事务量



**出现死锁后两种策略**

1. 一种策略是，直接进入等待，直到`超时`

   > 这个超时时间通过参数` innodb_lock_wait_timeout` 来设置，InnoDB中默认值是 50s
   >
   > 意味着当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行

2. 另一种策略是，发起`死锁检测`，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务可以继续执行

   > 参数 `innodb_deadlock_detect 设置为 on`，表示开启这个逻辑，默认就是on



正常情况下还是要采用第二种策略：主动死锁检测

```sql
// 死锁检测的开启和关闭，0为关闭检测
set global innodb_deadlock_detect=0;
```



```sql
mysql> show variables like 'innodb_lock_wait_timeout';
+--------------------------+-------+
| Variable_name            | Value |
+--------------------------+-------+
| innodb_lock_wait_timeout | 50    |
+--------------------------+-------+
1 row in set (0.00 sec)

mysql> show variables like 'innodb_deadlock_detect';
+------------------------+-------+
| Variable_name          | Value |
+------------------------+-------+
| innodb_deadlock_detect | ON    |
+------------------------+-------+
1 row in set (0.05 sec)
```



开启`主动死锁检测`时，每当一个事务被锁时，就要看看它所依赖的线程有没有被别人锁住（这是一个时间复杂度是` O(n) `的操作），如此循环，最后判断是否出现了循环等待，也就是死锁

> 假设有` 1000 个并发线程要同时更新同一行`，那么死锁检测操作就是 `100 万`这个量级的。虽然最终检测的结果是没有死锁，但是这期间要`消耗大量的 CPU 资源`。因此就会出现 CPU 利用率很高，但是每秒却执行不了几个事务



**怎么解决由这种`热点行`更新导致的性能问题(死锁检测要耗费大量的 CPU 资源)呢？**

1. 如果能确保这个业务一定不会出现死锁，可以`临时把死锁检测关掉`

   > 但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的

2. 另一个思路是`控制并发度`

   > 如果并发能够控制住，比如`同一行同时最多只有 10 个线程在更新`，那么死锁检测的成本很低，就不会出现这个问题
   >
   > 这个并发控制要做在`数据库服务端`。如果你有中间件，可以考虑在中间件实现；也可以做在 MySQL 里面，基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了

   > 不可以在客户端做并发控制。因为客户端很多，假设有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000

3. 能不能从设计上优化这个问题呢？

可以考虑通过将一行改成逻辑上的`多行来减少锁冲突`

> 还是以影院账户为例，可以考虑`放在多条记录上`，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗
>
> 这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。


