# 索引的作用

为了提高数据查询的效率

> MySQL的索引是在`存储引擎层`实现的



# 索引的常见的3种数据结构

## 1、哈希表

**优点：**

根据`键查找方便`，适合等值查询



**缺点：**

1. 键值对存储，会有哈希冲突

2. 不适合做范围查询

   > 数据的存储不是有序的，所以查询某个范围的数据`只能遍历整个哈希表`



## 2、有序数组

**优点：**

1. 适合等值查询（二分查找O(log(N))）
2. 适合范围查询（先用二分查找找到，然后范围区间的左边值，然后向右遍历取值即可）

**缺点**

1. 不适合插入数据

   > 数组插入数据需要移动该位置后的数据，所以有序数组适用于静态数组存储静态数据（这类数据不会改变）



## 3、搜索树

树可以有二叉，也可以有多叉

> 多叉树就是每个节点有多个儿子，儿子之间的`大小保证从左到右递增`



#### **二叉搜索树**

**二叉搜索树的特点**

父节点左子树所有结点的值`小于父节点`的值，右子树所有结点的值`大于父节点`的值。

> 为了维持 O(log(N)) 的查询复杂度，就需要保持这棵树是`平衡二叉树`，为了做这个保证，更新的时间复杂度也是 O(log(N))



**优点**

搜索效率最高



**缺点**

二叉树树高过高，每次查询都需要访问过多节点，即访问数据块过多，而从磁盘`随机读取`数据块过于耗时，因为索引不止存在内存中，还要写到磁盘上

> 可以想象一下一棵 100 万节点的平衡二叉树，树高 20。
>
> 一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，`单独访问一个行`可能需要 20 个 10 ms 的时间，太慢了
>



#### N叉树

**优点**

查询过程访问的数据块比二叉树少，即读磁盘次数更少



**“N 叉”树中的“N”取决于数据块的大小**

以 InnoDB 的一个`整数字段索引`为例，这个 N 差不多是 1200。这棵树高是 4 时，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到`树根的数据块总是在内存中的`，一个 10 亿行的表上一个整数字段的索引，查找一个值`最多只需要访问3次磁盘`。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

> MySql默认一个节点的长度为`16K`，一个整数（bigint）字段索引的长度为 8B，另外每个索引还跟着6B的指向其子树的指针；所以`16K/14B ≈ 1170`



# InnoDB的索引（B+树）

## 索引组织表

在 InnoDB中，表都是根据`主键顺序`以索引的形式存放的，这种存储方式的表称为`索引组织表`。



InnoDB 使用了 B+ 树索引模型，B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。



## 聚簇索引 和 二级索引

每一个索引在 InnoDB 里面对应一棵`B+ 树`，根据`叶子节点的内容`，索引类型分为`主键索引`和`非主键索引`。



* 主键索引的叶子节点存的是`整行数据`。在 InnoDB，主键索引也被称为`聚簇索引（clustered index）`

* 非主键索引的叶子节点存的是`主键的值`。在 InnoDB，非主键索引也被称为`二级索引（secondary index）`



**基于主键索引和普通索引的查询有什么区别？**

* 如果语句是 `select * from T where ID=500`，即主键查询方式，则只需要搜索 ID 这棵 B+ 树
* 如果语句是 `select * from T where k=5`（k有索引），即普通索引查询方式，则需要先搜索` k索引树`，得到 ID 的值为 500，再到` ID 索引树`搜索一次。这个过程称为`回表。`



# 索引维护

B+ 树为了维护`索引有序性`，在插入新值时需要做必要的维护。



如图，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就`需要逻辑上挪动后面的数据`，空出位置。

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/20210719224056.png)

## 页分裂

如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时需要`申请一个新的数据页`，然后`挪动部分数据过去`。这个过程称为`页分裂`。在这种情况下，性能自然会受影响。



**缺点：**

* 性能会受影响
* 影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%



## 页合并

当相邻两个页由于`删除了数据`，利用率很低之后，会将数据页做合并。



## 自增主键 和 业务主键

**自增主键**

自增主键是指`自增列上定义的主键`，在建表语句中一般是这么定义： `NOT NULL PRIMARY KEY AUTO_INCREMENT`

> 插入新记录的时可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。



优点：

* 性能方面：自增主键的插入数据模式正符合前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。
* 存储空间方面：自增主键长度一般比较短，占空间少



**业务主键**

即有`业务逻辑`的字段做主键



缺点：

* 性能方面：不容易保证有序插入，这样写数据成本相对较高
* 存储空间方面：业务主键一般比较长；主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越少



假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用`身份证号`做主键，还是用`自增字段`做主键呢？

> 由于每个非主键索引的叶子节点上都是主键的值。如果用`身份证号`做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用`整型`做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节



**什么场景适合用`业务字段`直接做主键**

1. 只有一个索引
2. 该索引必须是唯一索引

这就是典型的 KV 场景。由于没有其他索引，所以也就`不用考虑其他索引的叶子节点大小`的问题。



# InnoDB使用B+树的原因

## MySQL的存储结构

表存储结构，单位：表>段>区>页>行



在数据库中， 不论读一行，还是读多行，都是将这些行所在的页进行加载。也就是说存储空间的基本单位是`页`



一个页就是一棵树B+树的节点，`数据库I/O操作`的最小单位是页，与数据库相关的内容都会存储在页的结构里。



## B+树索引结构

在一棵B+树中，每个节点为都是一个页，每次新建节点时，就会`申请一个页空间`。



同一层的节点为之间，通过页的结构构成了一个`双向链表。`



**非叶子节点**

包括了多个索引行，每个索引行里存储`索引键`和`指向下一层页面的指针`

**叶子节点**

存储了关键字和行记录，在节点内部(也就是页结构的内部)记录之间是一个单向的表



## B+树页节点结构

**特点**

1. 将所有的记录分成几个组， 每组会存储多条记录

2. 页目录存储的是`槽(slot)`，槽相当于分组记录的索引，每个槽指针指向了不同组的最后一个记录

3. 我们通过槽定位到组，再查看组中的记录



**页的主要作用**

存储记录，在页中记录以`单链表`的形式进行存储



单链表优点是`插入、删除方便`，缺点是`检索效率不高`，最坏的情况要遍历链表所有的节点。因此页目录中提供了二分查找的方式，来提高记录的检索效率。



## B+树的检索过程

1. 从B+树的根开始，逐层找到叶子节点

2. 找到叶子节点为对应的数据页，将数据页加载到内存中，通过页目录的槽采用二分查找的方式先找到一个粗略的记录分组

3. 在分组中通过链表遍历的方式进行记录的查找



## 为什么要用B+树索引

数据库访问数据要通过页，一个页就是一个B+树节点，访问一个节点相当于一次I/O操作，所以越快能找到节点，查找性能越好。



B+树的特点就是够矮够胖，能有效地减少访问节点次数从而提高性能。



**对比一下二叉树、多叉树、B树和B+树**

1. 二叉树

二叉树是一种二分查找树，有很好的查找性能，相当于二分查找。

但是当N比较大时，树的深度比较高。数据查询的时间主要依赖于磁盘IO的次数，二叉树深度越大，查找的次数越多，性能越差。

最坏的情况是退化成了链表，为了让二叉树不至于退化成链表，人们发明了AVL树(平衡二叉搜索树)：任何结点的左子树和右子树高度最多相差1



2. 多叉树

多叉树就是节点可以是M个，能有效地减少高度，高度变小后，节点变少I/O自然少，性能比二叉树好了



3. B树

B树简单地说就是多叉树，每个叶子会存储数据，和指向下一个节点的指针。



例如要查找9，步骤如下

我们与根节点的关键字 (17，35)进行比较，9 小于 17 那么得到指针 P1；

按照指针 P1 找到磁盘块 2，关键字为(8，12)，因为 9 在 8 和 12 之间，所以我们得到指针 P2；

按照指针 P2 找到磁盘块 6，关键字为(9，10)，然后我们找到了关键字 9。



4. B+树

B+树是B树的改进，简单地说是：只有叶子节点才存数据，非叶子节点是存储的指针；所有叶子节点构成一个`有序链表`



例如要查找关键字16，步骤如下

与根节点的关键字 (1，18，35) 进行比较，16 在 1 和 18 之间，得到指针 P1(指向磁盘块 2)

找到磁盘块 2，关键字为(1，8，14)，因为 16 大于 14，所以得到指针 P3(指向磁盘块 7)

找到磁盘块 7，关键字为(14，16，17)，然后我们找到了关键字 16，所以可以找到关键字 16 所对应的数据。



## B+树与B树的不同

* B+树非叶子节点不存在数据只存索引，B树非叶子节点存储数据

* B+树使用链表连接所有叶子节点，区间查询效率更高，因为所有数据都在B+树的叶子节点，但是B树则需要通过`中序遍历`才能完成查询范围的查找

* B+树每次都必须查询到叶子节点才能找到数据，而B树查询的数据可能不在叶子节点，也可能在，这样就会造成`查询的效率的不稳定`

* B+树查询效率更高，因为B+树矮更胖，高度小，`查询产生的I/O最少`



# 索引的概念

## 索引字段查询流程

T表的初始化语句

```sql
create table T (
    ID int primary key,
    k int NOT NULL DEFAULT 0, 
    s varchar(16) NOT NULL DEFAULT '',
    index k(k)) engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');
```

如果执行 `select * from T where k between 3 and 5`，需要执行几次树的搜索操作，会扫描多少行？



**这条 SQL 查询语句的执行流程：**

1. 在` k索引树`上找到 k=3 的记录，取得 ID = 300
2. 再到` ID索引树`查到 ID=300 对应的 R3
3. 在` k索引树`取下一个值 k=5，取得 ID=500
4. 再回到` ID索引树`查到 ID=500 对应的 R4
5. 在` k索引树取下一个值 k=6`，不满足条件，循环结束

在这个过程中，回到主键索引树搜索的过程，我们称为`回表`。这个查询过程`读了 k 索引树的 3 条记录（步骤 1、3 和 5）`，`回表了两次（步骤 2 和 4）`



## 覆盖索引

如果执行的语句是 `select ID from T where k between 3 and 5`，这时只需要查 ID 的值，`而 ID的值已经在 k 索引树上了`，因此可以直接提供查询结果，不需要`回表`。

也就是说，在这个查询里面，索引 k的数据已经“覆盖了”查询的需求，称为`覆盖索引`。



由于`覆盖索引`可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的`性能优化手段`。



需要注意的是，在`引擎内部`使用覆盖索引在索引 k 上其实读了`三个记录`，R3~R5（对应的索引 k 上的记录项），但是对于 MySQL 的 `Server 层`来说，它就是`找引擎拿到了两条记录`，因此 `MySQL认为扫描行数是 2`。



**讨论一个问题：在一个市民信息表上，是否有必要将`身份证号`和`名字`建立联合索引？**

假设这个市民表的定义是这样的：

```sql
CREATE TABLE `tuser` (
  `id` int(11) NOT NULL,
  `id_card` varchar(32) DEFAULT NULL,
  `name` varchar(32) DEFAULT NULL,
  `age` int(11) DEFAULT NULL,
  `ismale` tinyint(1) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `id_card` (`id_card`),
  KEY `name_age` (`name`,`age`)
) ENGINE=InnoDB
```



身份证号是市民的唯一标识。

也就是说，如果有根据`身份证号`查询市民信息的需求，只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？

> 如果现在有一个`高频请求`，要根据`市民的身份证号查询他的姓名`，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，`不再需要回表查整行记录，减少语句的执行时间`。



## 最左前缀原则

如果现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？

反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该怎么做呢？



B+ 树这种索引结构，可以利用`索引的“最左前缀”`，来定位记录。

> 我们用（name，age）这个`联合索引`来分析，索引项是按照`索引定义里面出现的字段顺序排序`的。



不只是索引的全部定义，只要`满足最左前缀`，就可以利用索引来加速检索。这个最左前缀可以是`联合索引的最左 N 个字段`，也可以是`字符串索引的最左M个字符`。



**在建立联合索引时，如何安排索引内的字段顺序**

评估标准是，索引的`复用能力`。

> 因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。
>
> 因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。



如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。

> 这时我们要考虑的原则就是空间了。
>
> 比如上面这个市民表的情况，name 字段是比 age 字段大的 ，所以建议创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。



## 索引下推

> MySQL5.6之后有索引下推

前提：有对应的联合索引可以利用



如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。

> 以市民表的`联合索引（name, age）`为例

SQL 语句如下：

```sql
 select * from tuser where name like '张%' and age=10 and ismale=1;
```

根据`前缀索引规则`，所以这个语句在搜索索引树时，`只能用 “张”`，找到第一个满足条件的记录 ID3。然后判断其他条件是否满足（当然，这还不错，总比全表扫描要好）



在 MySQL 5.6 之前，只能从 `ID3 开始一个个回表`。到主键索引上找出数据行，再对比字段值。

在无索引下推中，这个`过程InnoDB并不会去看 age 的值`，只是按顺序把“name 第一个字是’张’”的记录`一条条取出来回表`。因此，需要回表 4 次。



`无索引下推执行流程图`

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/05_%E7%B4%A2%E5%BC%95_01.jpg)



而 MySQL 5.6 引入的`索引下推优化（index condition pushdown)`， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。



在有索引下推中，InnoDB 在 `(name,age) 索引`内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要`回表 2 次`。



`有索引下推执行流程图`

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/05_%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95_02.jpg)



## 字符串的前缀索引

### 什么是前缀索引

MySQL支持`前缀索引`，也就是可以定义字符串的一部分作为索引

> 默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串



### 前缀索引的优缺点

1. 优点：索引树所占空间更小

2. 缺点：如果查询到email前缀匹配的数据，此时会`回表`去主键树查email字段的完整数据看是否匹配，不匹配则记录取二级索引树的下一条数据重复以上操作，即`增加额外的记录扫描次数`



### 例子

假如用户表里有个邮箱email字段，系统支持`邮箱登陆`，此时会以email作为查询条件，建表语句如下

```sql
create table SUser(
  ID bigint unsigned primary key,
  email varchar(64)
)engine=innodb;
```

此时要怎么给email字段加索引呢



**1. 为email整个字段创建索引**

```sql
alter table SUser add index index1(email);
```

**2. 为email字段的前6个字符创建索引**

> 注意此时索引树中只会包含email的前6个字符

```sql
alter table SUser add index index2(email(6));
```



看下在这两个索引定义下该查询语句分别是怎么执行的

```sql
select id,name,email from SUser where email='zhangssxyz@xxx.com';
```



**如果使用的是index1( email 整个字符串的索引结构)，执行顺序如下：**

1. 从 index1 索引树找到满足索引值是`’zhangssxyz@xxx.com’`的这条记录，取得 ID2 的值
2. 到`主键索引上`查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集
3. 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 `email='zhangssxyz@xxx.com’`的条件了，循环结束

这个过程中，只需要回`主键索引`取一次数据，所以系统认为`只扫描了一行`



**如果使用的是index2( email(6) 索引的结构)，执行顺序如下：**

1. 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1
2. 到主键上查到主键值是 ID1 的行，判断出 email 的值不是`’zhangssxyz@xxx.com’`，这行记录丢弃；
3. 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集
4. 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束

在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行



**结论：**

使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本



### 怎么定义前缀的长度

实际上，在建立索引时关注的是`区分度`，区分度越高越好。因为区分度越高，意味着重复的键值越少。



因此，可以通过`统计索引上有多少个不同的值`来判断要使用多长的前缀。



1. 首先，算出这个列上有多少个不同的值：

```sql
select count(distinct email) as L from SUser;
```

2. 然后，依次选取不同长度的前缀来看这个值，比如要看一下` 4~7 个字节`的前缀索引

```sql
select 
  count(distinct left(email,4)）as L4,
  count(distinct left(email,5)）as L5,
  count(distinct left(email,6)）as L6,
  count(distinct left(email,7)）as L7,
from SUser;
```

当然，使用前缀索引很可能会损失区分度，所以需要预先设定一个可以接受的损失比例，比如 5%。

然后，在返回的` L4~L7 中`，找出不小于` L * 95% 的值`，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6



### 前缀索引对覆盖索引的影响

1. 前缀索引可能会`增加扫描行数`，这会影响到性能
2. 前缀索引`用不上`覆盖索引对查询性能的优化，如果查询结果需要email的值，需要回一次表去主键树查email的完整数据



# 其他方式来创建索引

假如现在要以`身份证号`来创建索引，需要怎么创建



**分析**

1. 身份证号比较长，整个字段创建索引`浪费空间`
2. 身份证号其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。所以需要选比较长的前缀创建前缀索引，这样也会浪费空间



**2种实现方式**

1. 使用`倒序存储`，再创建前缀索引

> 倒序用于绕过字符串本身前缀的区分度不够的问题
>
> 存储身份证号时把它倒过来存，查询时查询条件为倒过来的身份证号

2. 使用 hash 字段

> 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消
>
> 
>
> 在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。
>
> 在插入数据时，也计算后插入该hash字段的值（如使用crc32() 这个函数），查询时根据hash字段和身份证号查，因为hash可能有冲突，所以查询条件需要加上身份证号



**区别**

相同点：

以上两种方法都`不支持范围查询`，只能等值查询



不同点：

1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段

   > 当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了

2. 在 CPU 消耗方面，倒序方式每次写和读时，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些

3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些

   > 因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。



# 选错索引的情况

## 复现MySQL选错索引

### 建表语句

```sql
CREATE TABLE `t` ( 
    `id` int(11) NOT NULL auto_increment,
    `a` int(11) DEFAULT NULL,
    `b` int(11) DEFAULT NULL, 
    PRIMARY KEY (`id`), KEY `a` (`a`), KEY `b` (`b`)
) ENGINE=InnoDB;
```



建立存储过程并执行`call idata()`，插入10万条数据（本地耗时约为44.03秒）

```sql
delimiter ;;
create procedure idata()
begin 
  declare i int; 
  set i=1; 
		while(i<=100000) do 
		  insert into tt values(i, i, i); 
			set i=i+1;
	  end while;
end;;
delimiter ;
call idata();
```



### 分析执行sql命中索引情况

```sql
mysql> explain select * from tt where a between 10000 and 20000;
```

结果如下

```sql
+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+
| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows  | filtered | Extra                 |
+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+
|  1 | SIMPLE      | tt    | NULL       | range | a             | a    | 5       | NULL | 10001 |   100.00 | Using index condition |
+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+
1 row in set, 1 warning (0.00 sec)
```

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/20210629212041.png)

从结果中可见优化器选择了a为索引，符合预期



### 复现走错索引

注意：MySQL8.0.13复现不出本文中走错索引扫描全表的情况，需要用其他版本复现

| Session A                                   | Session B                                                 |
| ------------------------------------------- | --------------------------------------------------------- |
| start transaction with consistent snapshot; |                                                           |
|                                             | delete from tt;                                           |
|                                             | call idata();                                             |
|                                             | explain select * from tt where a between 10000 and 20000; |
| commit;                                     |                                                           |

这时session B 的查询语句 `select * from t where a between 10000 and 20000` 就`不会再选择索引 a `了



**步骤如下**

1. 设置开启慢日志(只对当前数据库有效，MySQL重启后失效)

```sql
set global slow_query_log=on;
```

2. 查看慢日志存储文件的位置

```sql
show variables like 'slow_query_log_file';
```

3. 开启两个MySQL实例，执行上面的语句

4. 查看慢日志文件，输出如下

```bash
/usr/local/mysql/bin/mysqld, Version: 8.0.13 (MySQL Community Server - GPL). started with:
Tcp port: 3306  Unix socket: /tmp/mysql.sock
Time                 Id Command    Argument
/usr/local/mysql/bin/mysqld, Version: 8.0.13 (MySQL Community Server - GPL). started with:
Tcp port: 3306  Unix socket: /tmp/mysql.sock
Time                 Id Command    Argument

# Time: 2021-06-29T13:38:55.134942Z
# User@Host: root[root] @ localhost []  Id:    13
# Query_time: 0.017072  Lock_time: 0.000105 Rows_sent: 10001  Rows_examined: 10001
SET timestamp=1624973935;
select * from tt where a between 10000 and 20000;
# Time: 2021-06-29T13:39:03.631562Z
# User@Host: root[root] @ localhost []  Id:    13
# Query_time: 0.013488  Lock_time: 0.000283 Rows_sent: 10001  Rows_examined: 10001
SET timestamp=1624973943;
select * from tt where a between 10000 and 20000;

# Time: 2021-06-29T13:45:57.196214Z
# User@Host: root[root] @ localhost []  Id:    13
# Query_time: 0.002059  Lock_time: 0.000000 Rows_sent: 0  Rows_examined: 0
SET timestamp=1624974357;
select * from t force index(a) where a between 10000 and 20000;
# Time: 2021-06-29T13:46:11.395209Z
# User@Host: root[root] @ localhost []  Id:    13
# Query_time: 0.000618  Lock_time: 0.000191 Rows_sent: 1  Rows_examined: 0
SET timestamp=1624974371;
explain select * from tt force index(a) where a between 10000 and 20000;
```

从慢日志中可以看到，前后执行了两次查询`select * from tt where a between 10000 and 20000;`后面执行了两次explain分析查询语句

* Query_time表示执行时间，单位为秒
* Rows_examined表示扫描的行数



可以用`force index(a)`指定查询语句强制走a索引

```sql
select * from t force index(a) where a between 10000 and 20000;
```



## 优化器：选择索引

选择索引是优化器的工作



**优化器选择索引的目的**

找到一个`最优的执行方案`，并用`最小的代价`去执行语句



在数据库里，`扫描行数`是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。



但扫描行数并不是唯一的判断标准，优化器还会结合是否`使用临时表`、`是否排序`等因素进行综合判断。



**扫描行数是怎么判断的?**

MySQL 只能根据`统计信息`来估算记录数。

这个统计信息就是`索引的“区分度”`。



显然，一个索引上不同的值越多，这个索引的区分度就越好。



而一个索引上不同的值的个数，称之为`“基数”（cardinality）`。也就是这个基数越大，索引的区分度越好。



`Cardinality字段`

```bash
mysql> show index from  tt;
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+
| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression |
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+
| tt    |          0 | PRIMARY  |            1 | id          | A         |      100256 |     NULL |   NULL |      | BTREE      |         |               | YES     | NULL       |
| tt    |          1 | a        |            1 | a           | A         |      100256 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
| tt    |          1 | b        |            1 | b           | A         |      100256 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+
3 rows in set (0.02 sec)
```



**MySQL 是怎样得到索引的基数的呢？**

利用采样统计

```sql
mysql> explain select * from tt where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;
+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+------------------------------------+
| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows  | filtered | Extra                              |
+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+------------------------------------+
|  1 | SIMPLE      | tt    | NULL       | range | a,b           | b    | 5       | NULL | 50128 |     1.00 | Using index condition; Using where |
+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+------------------------------------+
1 row in set, 1 warning (0.00 sec)
```

这次优化器选择了索引 b，而 rows 字段显示需要扫描的行数是 50128



## 选错索引的处理

1. 采用` force index `强行选择一个正确的索引
2. 可以考虑修改sql语句，引导 MySQL 使用我们期望的索引
3. 在有些场景下，可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引



# 普通索引和唯一索引的区别

## 前提：表T的建表语句

```sql
create table T(
    id int primary key, 
    k int not null, 
    name varchar(16),
    index (k)
) engine=InnoDB;
```



## 从性能角度考虑两者的区别

## 1、对查询语句性能的影响

两者对查询语句的性能`几乎无区别`



**分析**

```sql
-- 执行如下语句
select id from T where k=5
```

此语句先从B+树的树根开始，按层搜索到`叶子节点`(数据页)，然后可以认为数据页内部通过`二分法`来`定位记录`

* 如果k建立了`普通索引`，查找到满足条件的`第一个记录k=5后`，需要查找`下一个记录`，直到碰到`第一个不满足 k=5 `条件的记录
* 如果k建立了`唯一索引`，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会`停止继续检索`



这两种带来的性能差距是微乎其微的，因为

1. InnoDB 的数据是按`数据页`为单位来`读写`的

   > 当需要读一条记录时，并不是将这个记录本身从磁盘读出来，而是`以页为单位`，将其整体读入`内存`。
   >
   > 在 InnoDB 中，每个数据页的大小默认是 `16KB`

2. 因为引擎是按页读写的，当找到 k=5 的记录时，`它所在的数据页就都在内存里了`。对于普通索引来说，要多做的那一次`“查找和判断下一条记录”`的操作，就只需要`一次指针寻找`和`一次计算`

3. 当然，如果 k=5 这个记录刚好是`这个数据页的最后一个记录`，那么要取下一个记录，必须`读取下一个数据页`，这个操作会稍微复杂一些

4. 对于`整型字段`，一个`数据页`可以放`近千个 key`，因此出现步骤3这种情况的概率会很低，对性能的影响可以忽略不计

   

## 2、对更新语句性能的影响

### **更新一个数据页的流程**

1. 当需要更新一个数据页时，数据页在内存中，直接更新
2. 数据页不在内存中，在`不影响数据一致性`的前提下，InnoDB 将更新操作`缓存到change buffer中`，不需要从磁盘读入这个数据页
3. 下次查询时要访问这个数据页，才将数据页`读入内存`，然后执行change buffer中与这个页有关的操作



### Change buffer

#### 什么是 change buffer

change buffer记录了数据页的`更新操作的缓存`，存在内存中，也会被`写入到磁盘上`，会持久化数据



#### change buffer的大小

change buffer 用的是 `buffer pool `里的内存，因此`不能无限增大`。



change buffer 的大小，通过参数` innodb_change_buffer_max_size `来动态设置。

设置为 50 时，表示 change buffer 的大小`最多只能占用 buffer pool 的 50%`



#### change buffer的作用

1. 将更新操作`先记录在change buffer`，`减少读磁盘`，更新语句的`执行速度`会得到明显的提升

2. 避免占用内存，提高`内存利用率`

   > 假设更新需要先读取数据入内存，而数据读入内存是需要`占用 buffer pool `的



#### 什么是merge

将 change buffer 中的操作`应用到原数据页`，得到`最新结果`的过程称为` merge` 



#### merge的时机

1. 访问这个数据页，把数据页读入内存时会触发
2. 系统有`后台线程会定期 merge`
3. 在数据库`正常关闭（shutdown）`的过程中，也会执行 merge 操作



#### 什么条件下使用change buffer 

`唯一索引的更新`不能使用，只有`普通索引`可以使用

> 对于`唯一索引`，所有的更新操作都要先判断这个操作`是否违反唯一性约束`

> 比如，要插入 k=4，要`先判断`表中是否已经存在 k=4 的记录，此时必须要`将数据页读入内存才能判断`
>
> （如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了）



**如果要在这张表中插入一个新记录 k=4 的话，InnoDB 的处理流程如下，分两种情况：**

1. 第一种情况是，这个记录要更新的目标页在`内存`中：

* 对于`唯一索引`，找到 3 和 5 之间的位置，判断到`没有冲突`，插入这个值，语句执行结束
* 对于`普通索引`，找到 3 和 5 之间的位置，插入这个值，语句执行结束

普通索引和唯一索引`对更新语句性能影响的差别`，只是`一个判断`，只会耗费微小的 CPU 时间



2. 第二种情况是，这个记录要更新的目标页`不在内存中`：

* 对于`唯一索引`，需要将数据页`读入内存`，判断到没有冲突，插入这个值，语句执行结束

* 对于`普通索引`，则是将`更新记录在 change buffer`，语句执行就结束了

  

将数据`从磁盘读入内存`涉及`随机 IO `的访问，是数据库里面成本最高的操作之一。

change buffer 因为`减少了随机磁盘访问`，所以对更新性能的提升是会很明显的。



#### change buffer 的使用场景

 `change buffer 对更新过程有加速作用`，change buffer 只限于用在`普通索引`的场景下，而`不适用于唯一索引`



**普通索引的所有场景使用 change buffer 都可以起到加速作用吗？**

1. merge 时才是真正`进行数据更新的时刻`，而 change buffer 的主要目的就是`将记录的变更动作缓存下来`，所以在一个数据页做 merge 之前，`change buffer 记录的变更越多`（也就是这个页面上要更新的次数越多），收益就越大

2. 对于`写多读少`的业务，页面在写完以后马上`被访问到的概率比较小`，此时 change buffer 的使用`效果最好`

   > 如`账单类、日志类`类系统

3. 如果业务是`更新之后马上会做查询`，即使满足了条件，将更新先记录在 change buffer，但由于马上要访问这个数据页，会`立即触发 merge 过程`。这样`随机访问 IO 的次数不会减少`，反而`增加了 change buffer 的维护代价`。所以，对于这种业务模式来说，change buffer 反而起到了副作用。



## change buffer 和 redo log

现在在表上执行这个插入语句：

```sql
insert into t(id,k) values(id1,k1),(id2,k2);
```



假设当`前 k 索引树`的状态，查找到位置后

* k1 所在的数据页`在内存 (InnoDB buffer pool) `中

* k2 所在的数据页`不在内存`中

  

如下图所示是`带 change buffer 的更新状态图`

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/09_%E7%B4%A2%E5%BC%95_01.png)



这条更新语句涉及了4个部分：

* 内存
* redo log（ib_log_fileX）
* 数据表空间（t.ibd）
* 系统表空间（ibdata1）



**这条更新语句做了如下的操作（按照图中的数字顺序）：**

1. Page 1 在内存中，直接更新内存
2. Page 2 没有在内存中，就在内存的` change buffer 区域记录下“我要往 Page 2 插入一行”这个信息`
3. 将上述两个动作记入` redo log 中`（图中的 3和4）

做完上面这些，`事务就可以完成了`。



所以，执行这条更新语句的成本很低，就是`写了两处内存`，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是`顺序写`的。

图中的两个虚线箭头，是`后台操作`，不影响更新的响应时间。



**那在这之后的读请求，要怎么处理呢？**

比如，现在要执行` select * from t where k in (k1, k2)`



如果读语句发生在更新语句后`不久`，内存中的数据都还在，那么此时的`这两个读操作`就与`系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了`，所以图中就没画出这两部分，如下图`带 change buffer 的读过程`

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/09_%E7%B4%A2%E5%BC%95_02.png)



从图中可以看到：

1. 读` Page 1 `时，直接`从内存返回`

   > WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。可以看一下图中这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的

2. 要`读 Page 2 `时，需要`把 Page 2 从磁盘读入内存中`，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果



可以看到，`直到需要读 Page 2 `时，这个数据页才会被读入内存。



**对比这两个机制在提升更新性能上的收益**

* redo log 主要节省的是`随机写磁盘`的 IO 消耗（转成顺序写）
* change buffer 主要节省的则是`随机读磁盘`的 IO 消耗



## 索引选择和实践

1. 唯一索引和普通索引在`查询能力`上是没差别的
2. 由于唯一索引用不上 change buffer 的优化机制，因此如果`业务可以接受`，从性能角度出发建议优先考虑`普通索引`
3. 如果所有的更新后面都马上伴随着对这个记录的查询，那么应该`关闭 change buffer`。而在其他情况下，change buffer 都能提升更新性能
4. 在业务可能无法确保数据不重复下，是否使用唯一索引

* 首先，业务正确性优先

  > 一般是靠业务代码去保证唯一，如果业务不能保证不会写入重复数据，或者业务就是要求数据库来做约束，那就必须创建唯一索引。
  >

* 然后，在一些`“归档库”`的场景，你是可以考虑使用普通索引的

  > 比如，线上数据只需要保留半年，然后历史数据保存在归档库。
  >
  > 这时，归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引



# 类型转换导致索引失效

##  案例一：条件字段函数操作

假设现在维护了一个交易系统。



有一个交易记录表 tradelog： 包含交易流水号（tradeid）、交易员 id（operator）、交易时间（t_modified）等字段

```sql
CREATE TABLE `tradelog` (
  `id` int(11) NOT NULL,
  `tradeid` varchar(32) DEFAULT NULL,
  `operator` int(11) DEFAULT NULL,
  `t_modified` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `tradeid` (`tradeid`),
  KEY `t_modified` (`t_modified`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

**注意： CHARSET是utf8mb4**



假设，现在已经记录了从 2016 年初到 2018 年底的所有数据，运营部门有一个需求是，要`统计发生在所有年份中 7 月份的交易记录总数`

```sql
select count(*) from tradelog where month(t_modified)=7;
```

因为对t_modified字段做了函数计算，所以此时用不上t_modified的索引。



**对索引字段做函数操作，可能会`破坏索引值的有序性`，因此优化器就决定放弃走树搜索功能。**



**explain结果**

> 在测试表数据中插入了 10 万行数据

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/20210708222250.png)

* key="t_modified"表示的是，使用了t_modified 这个索引；

  > 在这个例子里，放弃了`树搜索功能`，优化器可以`选择遍历主键索引`，也可以选择遍历索引 t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会`选择索引 t_modified`。

* rows=100335，说明这条语句`扫描了整个索引的所有值`；

* Extra 字段的` Using index`，表示的是使用了`覆盖索引`

* 由于在 t_modified 字段加了 month() 函数操作，导致了全索引扫描



**类似使用不正确的语句还有**

```sql
select * from tradelog where id + 1 = 10000 // MySQL 优化器不会用 id 索引快速定位到 9999 这一行

// 应该改成
select * from tradelog where id = 10000 - 1；
```



**优化**

优化sql语句，使得用上t_modified索引的快速定位能力

```sql
select count(*) from tradelog where
 (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or
 (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or 
 (t_modified >= '2018-7-1' and t_modified<'2018-8-1');
```



## 案例二：隐式类型转换

如下语句，tradeid有索引，原表定义的tradeid是字符串类型varchar(32)，查询时用了整型，所以要做类型转换

```sql
select * from tradelog where tradeid=110717; 
```

 explain 结果显示这条语句需要走`全表扫描`，因为会做`类型转换`



### 数据类型转换的规则

**为什么有数据类型转换，就可能会走全索引扫描**



怎么判断是字符串转数字，还是数字转字符串?

有一个简单的方法，看 select '10' > 9 的结果：

1. 如果规则是“将字符串转成数字”，那么就是做`数字比较`，结果应该是 1
2. 如果规则是“将数字转成字符串”，那么就是做`字符串比较`，结果应该是 0

此时结果是1，说明是把字符串10转成了数字10



**所以MySQL 中，字符串和数字做比较的话，是`将字符串转换成数字`**



再看sql语句

```sql
select * from tradelog where tradeid=110717;
```

此时对于优化器来说，**会把字符串转成数字**，这个语句相当于：

```sql
select * from tradelog where  CAST(tradid AS signed int) = 110717;
```

这条语句触发了上面的规则：对索引字段做`函数操作`，优化器会放弃走树搜索功能，会走索引全表扫描。



如果执行这个语句则不会导致全表扫描；因为“字符串和数字做比较的话，是将字符串转换成数字”。

所以是在值“83126”上进行`函数操作`而不是在索引id上

```sql
select * from tradelog where id="83126"; // id是整型
```



## 案例三：隐式字符编码转换

假设系统里还有另外一个表` trade_detail`，用于记录`交易的操作细节`。



先往交易日志表 tradelog 和交易详情表 trade_detail 里插入一些数据

```sql
CREATE TABLE `trade_detail` (
  `id` int(11) NOT NULL,
  `tradeid` varchar(32) DEFAULT NULL,
  `trade_step` int(11) DEFAULT NULL, /*操作步骤*/
  `step_info` varchar(32) DEFAULT NULL, /*步骤信息*/
  PRIMARY KEY (`id`),
  KEY `tradeid` (`tradeid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8; /*注意这里是utf8*/

insert into tradelog values(1, 'aaaaaaaa', 1000, now());
insert into tradelog values(2, 'aaaaaaab', 1000, now());
insert into tradelog values(3, 'aaaaaaac', 1000, now());

insert into trade_detail values(1, 'aaaaaaaa', 1, 'add');
insert into trade_detail values(2, 'aaaaaaaa', 2, 'update');
insert into trade_detail values(3, 'aaaaaaaa', 3, 'commit');
insert into trade_detail values(4, 'aaaaaaab', 1, 'add');
insert into trade_detail values(5, 'aaaaaaab', 2, 'update');
insert into trade_detail values(6, 'aaaaaaab', 3, 'update again');
insert into trade_detail values(7, 'aaaaaaab', 4, 'commit');
insert into trade_detail values(8, 'aaaaaaac', 1, 'add');
insert into trade_detail values(9, 'aaaaaaac', 2, 'update');
insert into trade_detail values(10, 'aaaaaaac', 3, 'update again');
insert into trade_detail values(11, 'aaaaaaac', 4, 'commit');
```



如果要查询 id=2 的交易的所有操作步骤信息SQL 语句

```sql
select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/
```

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/20210708225635.png)

**explain结果**

1. 第一行显示优化器会`先在交易记录表 tradelog 上查到 id=2 的行`，这个步骤用上了主键索引，rows=1 表示只扫描一行
2. 第二行 key=NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了`全表扫描`



在这个执行计划里，是从 tradelog 表中取 tradeid 字段，再去 trade_detail 表里查询匹配字段。因此，我们把 `tradelog 称为驱动表`，把 `trade_detail 称为被驱动表`，把` tradeid 称为关联字段`。



explain 结果执行流程

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/18_%E8%AF%AD%E5%8F%A5Q1%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B)

1. 第 1 步，是根据 id 在 tradelog 表里找到 L2 这一行
2. 第 2 步，是从 L2 中取出 tradeid 字段的值
3. 第 3 步，是根据 tradeid 值到 trade_detail 表中查找条件匹配的行。explain 的结果里面第二行的 key=NULL 表示的就是，这个过程是通过`遍历主键索引`的方式，一个一个地判断 tradeid 的值是否匹配。



可以发现第 3 步不符合我们的预期。

> 因为表 trade_detail 里 tradeid 字段上是有索引的，我们本来是希望通过`使用 tradeid 索引`能够快速定位到等值的行。但这里并没有



**因为这`两个表的字符集不同`，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候`用不上关联字段的索引`。**



问题是出在执行步骤的第 3 步，如果单独把这一步改成 SQL 语句的话，那就是：

```sql
select * from trade_detail where tradeid=$L2.tradeid.value; 
```

其中，`$L2.tradeid.value` 的字符集是 utf8mb4。



字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较时，MySQL 内部的操作是，`先把 utf8 字符串转成 utf8mb4 字符集`，再做比较。



在执行上面这个语句时，需要`将被驱动数据表里的字段一个个地转换成 utf8mb4`，再跟 L2 做比较。

实际上这个语句等同于下面这个写法：

```sql
select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; 
```

CONVERT() 函数，把输入的字符串转成 utf8mb4 字符集



**这就触发了上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。**



字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。



作为对比验证，提另外一个需求，`“查找 trade_detail 表里 id=4 的操作，对应的操作者是谁”`，再来看下这个语句和执行计划

```sql
select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;
```

explain结果

![](https://sink-blog-pic.oss-cn-shenzhen.aliyuncs.com/img/mysql/20210708230343.png)

这个语句里 `trade_detail 表成了驱动表`，但是 explain 结果的第二行显示，这次的查询操作`用上了被驱动表 tradelog 里的索引 (tradeid)，扫描行数是 1`。



**问题**

为什么这次能用上被驱动表的 tradeid 索引呢



假设驱动表 trade_detail 里 id=4 的行记为 R4，那么在连接时，被驱动表 tradelog 上执行的就是类似这样的 SQL 语句：

```sql
select operator from tradelog  where traideid =$R4.tradeid.value; 
```



这时` $R4.tradeid.value `的字符集是 utf8, 按照字符集转换规则，要转成 utf8mb4，所以这个过程就被改写成：

```sql
select operator from tradelog where traideid =CONVERT($R4.tradeid.value USING utf8mb4);
```

这里的 CONVERT 函数是`加在输入参数上的`，这样就可以用上被驱动表的 traideid 索引。



**如果要优化下面语句的执行过程**

```sql
select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;
```



**有两种做法**

1. 比较常见的优化方法是，把 trade_detail 表上的 tradeid 字段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了

   ```sql
   alter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null;
   ```

2. 如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大， 或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了。

   ```sql
   select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; 
   ```

   主动把 l.tradeid 转成 utf8，就避免了被驱动表上的字符编码转换，从 explain 结果可以看到，这次索引走对了

